{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Example 1\n",
    "For this example, we have images of cars and flowers, which have been divided into training and testing sets, and we have to build a CNN that identifies whether an image is a car or a flower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the numpy library and the necessary Keras libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Now, set a seed and initiate the model with the `Sequential` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a seed\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add the first layer of the CNN, set the input shape to (64, 64, 3), the dimension of each image, and set the activation function as a ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential(name='CNN1')\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu', name='Conv2D_1'))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Now, add the pooling layer with the image size as 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " MaxPool2D_1 (MaxPooling2D)  (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(MaxPool2D(pool_size=(2, 2), name='MaxPool2D_1'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Flatten the output of the pooling layer by adding a flattening layer to the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " MaxPool2D_1 (MaxPooling2D)  (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " Flatten_1 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Flatten(name='Flatten_1'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Add the first Dense layer of the MLP. \n",
    "Here, 128 is the output of the number of nodes. As a good practice, 128 is good to get started. activation is relu. As a good practice, the power of two is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " MaxPool2D_1 (MaxPooling2D)  (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " Flatten_1 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               3936384   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,937,280\n",
      "Trainable params: 3,937,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(units=128, activation='relu', name='Dense_1'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add the output layer of the MLP.\n",
    "This is a binary classification problem, so the size is 1 and the activation is `sigmoid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " MaxPool2D_1 (MaxPooling2D)  (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " Flatten_1 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               3936384   \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,937,409\n",
      "Trainable params: 3,937,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Compile the network\n",
    "Use an adam optimizer and compute the accuracy during the training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Create training and test data generators. \n",
    "- Rescale the training and test images by `1/255` so that all the values are between `0` and `1`.\n",
    "- Set these parameters for the training data generators only \n",
    " - `shear_range=0.2`, `zoom_range=0.2`, and `horizontal_flip=True`\n",
    " \n",
    " - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,  shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create a training set from the training set folder.\n",
    "'training_set' is the folder where our data has been placed. Our CNN model has an image size of `64x64`, so the same size should be passed here too. `batch_size` is the number of images in a single batch, which is `32`. `Class_mode` is set to binary since we are working on binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create separate folders for our 2 classes and put the images in the respective folders.\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "DATA_ROOT = r'D:\\Study 2018 and later\\Mignimind Bootcamp\\Code\\P5-WarmUp\\Data for all Projects'\n",
    "\n",
    "car_flower_small = os.path.join(DATA_ROOT, 'car_flower_small')\n",
    "car = os.path.join(DATA_ROOT, 'car_flower_small/Car')\n",
    "flower = os.path.join(DATA_ROOT, 'car_flower_small/Flower')\n",
    "train = os.path.join(DATA_ROOT, 'car_flower_small/train')\n",
    "test = os.path.join(DATA_ROOT, 'car_flower_small/test')\n",
    "train_car = os.path.join(DATA_ROOT, 'car_flower_small/train/Car')\n",
    "train_flower = os.path.join(DATA_ROOT, 'car_flower_small/train/Flower')\n",
    "test_car = os.path.join(DATA_ROOT, 'car_flower_small/test/Car')\n",
    "test_flower = os.path.join(DATA_ROOT, 'car_flower_small/test/Flower')\n",
    "\n",
    "try :\n",
    "    os.mkdir(os.path.join(DATA_ROOT, car))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, flower))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, train))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, test))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, train_car))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, train_flower))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, test_car))\n",
    "    os.mkdir(os.path.join(DATA_ROOT, test_flower))\n",
    "    \n",
    "except FileExistsError:\n",
    "    print('Directories already exist')\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    # move all files starting with 'car' to the car folder\n",
    "    for file in os.listdir(car_flower_small):\n",
    "        if file.startswith('car'):\n",
    "            shutil.move(os.path.join(car_flower_small, file), car)\n",
    "    # move all files starting with 'flower' to the flower folder\n",
    "    for file in os.listdir(car_flower_small):\n",
    "        if file.startswith('flower'):\n",
    "            shutil.move(os.path.join(car_flower_small, file), flower)\n",
    "except FileNotFoundError:\n",
    "    print('Files already moved')\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    # move 80 of the images from Car folder to test/Car folder\n",
    "    for file in random.sample(os.listdir(car), 80):\n",
    "        shutil.move(os.path.join(car,file), test_car)\n",
    "\n",
    "    # move 80 of the images from Flower folder to test/Flower folder\n",
    "    for file in random.sample(os.listdir(flower), 80):\n",
    "        shutil.move(os.path.join(flower,file), test_flower)\n",
    "\n",
    "    # move remaining images from Car folder to train/Car folder\n",
    "    for file in os.listdir(car):\n",
    "        shutil.move( os.path.join(car,file) , train_car)\n",
    "\n",
    "    # move remaining images from Flower folder to train/Flower folder\n",
    "    for file in os.listdir(flower):\n",
    "        shutil.move( os.path.join(flower,file), train_flower)\n",
    "except FileNotFoundError:\n",
    "    print('Files already moved')\n",
    "    pass\n",
    "except ValueError:\n",
    "    print('Files already moved')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1837 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set_gen = train_datagen.flow_from_directory(directory=train, target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Repeat step 10 for the test set \n",
    "while setting the folder to the location of the test images, that is, 'test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set_gen = test_datagen.flow_from_directory(test, target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Finally, fit the data. \n",
    "Set the `steps_per_epoch` to `STEP_SIZE_TRAIN` and the `validation_steps` to `STEP_SIZE_TEST`. \n",
    "\n",
    "Why do we need `steps_per_epoch` ?\n",
    "\n",
    "Keep in mind that a Keras data generator is meant to loop infinitely — it should never return or exit.\n",
    "\n",
    "Since the function is intended to loop infinitely, Keras has no ability to determine when one epoch starts and a new epoch begins.\n",
    "\n",
    "Therefore, we compute the `steps_per_epoch` value as the total number of training data points divided by the batch size. Once Keras hits this step count it knows that it’s a new epoch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* when I was running this code, I got an error saying that some errors are present when loading images. We need to get rid of corrupted images first. I used this code to get rid of corrupted images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\Car',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\Flower',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\test',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\test\\\\Car',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\test\\\\Flower',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\train',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\train\\\\Car',\n",
       " 'D:\\\\Study 2018 and later\\\\Mignimind Bootcamp\\\\Code\\\\P5-WarmUp\\\\Data for all Projects\\\\car_flower_small\\\\train\\\\Flower']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in os.walk(car_flower_small)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing:  D:\\Study 2018 and later\\Mignimind Bootcamp\\Code\\P5-WarmUp\\Data for all Projects\\car_flower_small\\train\\Car\\car.1115.jpg\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import load_img\n",
    "from PIL import UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for folder in [x[0] for x in os.walk(car_flower_small)]:\n",
    "    # print (folder)\n",
    "    for filename in os.scandir(folder):\n",
    "        if filename.is_file():\n",
    "            # print(filename)\n",
    "            try:\n",
    "                # print('Loading', filename.path)\n",
    "                load_img(filename.path)\n",
    "        \n",
    "           \n",
    "            except UnidentifiedImageError:\n",
    "                print(\"Removing: \", filename.path)\n",
    "                os.remove(filename.path)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* since we deleted 1 corrupted picture , we need to rerun out generators/iterators code if fir throws an non existing file error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "5\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 5s 86ms/step - loss: 0.4584 - accuracy: 0.7934 - val_loss: 0.4745 - val_accuracy: 0.7937\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 5s 82ms/step - loss: 0.4335 - accuracy: 0.7950 - val_loss: 0.4895 - val_accuracy: 0.7812\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 5s 86ms/step - loss: 0.4288 - accuracy: 0.7967 - val_loss: 0.4853 - val_accuracy: 0.7750\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.3957 - accuracy: 0.8310 - val_loss: 0.4656 - val_accuracy: 0.7875\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3883 - accuracy: 0.8349 - val_loss: 0.4933 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eeeea2e880>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=training_set_gen.n//training_set_gen.batch_size\n",
    "STEP_SIZE_TEST=test_set_gen.n//test_set_gen.batch_size\n",
    "print (STEP_SIZE_TRAIN)\n",
    "print (STEP_SIZE_TEST)\n",
    "\n",
    "classifier.fit(training_set_gen, steps_per_epoch=STEP_SIZE_TRAIN, epochs=5, validation_data=test_set_gen, validation_steps=STEP_SIZE_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef1714e42b4def67e43b690b68cb5e32caad528900a06884174db82a0752f8b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
